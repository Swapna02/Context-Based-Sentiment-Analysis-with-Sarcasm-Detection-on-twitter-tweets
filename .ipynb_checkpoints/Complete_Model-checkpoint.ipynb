{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import spacy\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import bz2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic decided is for  The president greets the press in chicago.  is  ['politics']\n"
     ]
    }
   ],
   "source": [
    "#Context deciding\n",
    "with open(\"model_pickle\",\"rb\") as f:\n",
    "    g1 = pickle.load(f)\n",
    "sentence = \"The president greets the press in chicago.\"\n",
    "print(\"topic decided is for \",sentence,\" is \",g1.predict([sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between sentence 1(The president greets the press in chicago.) and sentence 2(Obama is speaks to the media in Illinois.) is \n",
      "0.8788223685599832\n"
     ]
    }
   ],
   "source": [
    "#similarity deciding\n",
    "nlp=spacy.load('en_core_web_lg')\n",
    "doc1 = nlp(\"The president greets the press in chicago.\")\n",
    "doc2 = nlp(\"Obama is speaks to the media in Illinois.\")\n",
    "print(\"similarity between sentence 1(The president greets the press in chicago.) and sentence 2(Obama is speaks to the media in Illinois.) is \")\n",
    "print(doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 32)            96032     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 120,929\n",
      "Trainable params: 120,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 32, 32)            96000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 129,141\n",
      "Trainable params: 129,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#sarcasm deciding\n",
    "model1 = load_model('sarcasm_model1.h5')\n",
    "model1.summary()\n",
    "model2 = load_model('sarcasm_model2.h5')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentiment_model\",\"rb\") as f:\n",
    "    model3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=3000\n",
    "embedding_dim=32\n",
    "max_len=32\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "tokenizer= Tokenizer(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=[\"you broke my car , good job\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=tokenizer.texts_to_sequences(sent)\n",
    "padded=pad_sequences(seq,maxlen=max_len,padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you broke my car , good job']  from model1   [[0.16133708]]\n",
      "['you broke my car , good job']  from model2   [[0.08408633]]\n"
     ]
    }
   ],
   "source": [
    "print(sent,\" from model1  \",model1.predict(padded))\n",
    "print(sent,\" from model2  \",model2.predict(padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for     ' i am a good boy '   sentiment is  [1]\n"
     ]
    }
   ],
   "source": [
    "#sentiment deciding\n",
    "sen = \"i am a good boy\"\n",
    "dd = pd.DataFrame([[sen]],columns=['data'])\n",
    "with open(\"count_v.pkl\",\"rb\") as f:\n",
    "    vec1 = pickle.load(f)\n",
    "vec = CountVectorizer(decode_error=\"replace\", vocabulary=vec1)\n",
    "print(\"for     '\" , sen, \"'   sentiment is \",model3.predict(vec.transform(dd['data'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
